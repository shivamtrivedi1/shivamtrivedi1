{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "AutoKeras.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi3ac-vwyInD"
      },
      "source": [
        "# Auto-Keras (0.4)\n",
        "This notebook contains the experiments with AutoKeras, analyzing the quality and performance of the generated models and comparing them to handcrafted ones.\n",
        "\n",
        "Main questions:\n",
        "*   What does the structure of the generated networks look like?\n",
        "*   How is the quality compared to handmade nets?\n",
        "\n",
        "\"Auto-Keras is an open source software library for automated machine learning (AutoML). It is developed by DATA Lab at Texas A&M University and community contributors. The ultimate goal of AutoML is to provide easily accessible deep learning tools to domain experts with limited data science or machine learning background. Auto-Keras provides functions to automatically search for architecture and hyperparameters of deep learning models.\" - *autokeras.com*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mxv9oNAzBCH"
      },
      "source": [
        "## Packages and Imports\n",
        "The following section contains the packages that need to be installed and imported.\n",
        "\n",
        "Notice: In google colab you have to **restart the environment** after installing autokeras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esul44Nf4ss6"
      },
      "source": [
        "!pip install autokeras==0.4.0 # Version 0.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAbrvCgDvpj1"
      },
      "source": [
        "!python -V # Should output 3.6.* to work"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojYaKiCp4UYA"
      },
      "source": [
        "import autokeras as ak\n",
        "from autokeras.image.image_supervised import ImageClassifier\n",
        "from autokeras.utils import pickle_from_file\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noHgWmt5URPr"
      },
      "source": [
        "## Load data set\n",
        "In the following sections you can load the data set you are going to use to test Auto-Keras. The training data is contained in `x_train` and `y_train`, while the test data is in `x_test` and `y_test`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdB6pKeJ4UYE"
      },
      "source": [
        "### [MNIST](http://yann.lecun.com/exdb/mnist/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uors7eXJ4UYG"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape + (1,))\n",
        "x_test = x_test.reshape(x_test.shape + (1,))\n",
        "data_set_name = \"mnist\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVvqAmbQUjNt"
      },
      "source": [
        "### [Fashion-MNIST](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIlzNkL8Ul9q"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape + (1,))\n",
        "x_test = x_test.reshape(x_test.shape + (1,))\n",
        "data_set_name = \"fashion_mnist\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SKWl8dEUnXm"
      },
      "source": [
        "### [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYMLxSwIUmkL"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.reshape(x_train.shape + (1,))\n",
        "x_test = x_test.reshape(x_test.shape + (1,))\n",
        "data_set_name = \"cifar_10\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDRCmNq-V5FP"
      },
      "source": [
        "### [MHSMA](https://github.com/soroushj/mhsma-dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4h30uioV5Sl"
      },
      "source": [
        "!git clone https://github.com/soroushj/mhsma-dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55G9MpSfWwD_"
      },
      "source": [
        "# 64x64-pixel version of x\n",
        "x_train = np.load(\"mhsma-dataset/mhsma/x_64_train.npy\")\n",
        "x_test = np.load(\"mhsma-dataset/mhsma/x_64_test.npy\")\n",
        "x_train = x_train.reshape(x_train.shape + (1,))\n",
        "x_test = x_test.reshape(x_test.shape + (1,))\n",
        "\n",
        "# Different y labels\n",
        "y_acrosome_train = np.load(\"mhsma-dataset/mhsma/y_acrosome_train.npy\")\n",
        "y_acrosome_test = np.load(\"mhsma-dataset/mhsma/y_acrosome_test.npy\")\n",
        "y_head_train = np.load(\"mhsma-dataset/mhsma/y_head_train.npy\")\n",
        "y_head_test = np.load(\"mhsma-dataset/mhsma/y_head_test.npy\")\n",
        "y_vacuole_train = np.load(\"mhsma-dataset/mhsma/y_vacuole_train.npy\")\n",
        "y_vacuole_test = np.load(\"mhsma-dataset/mhsma/y_vacuole_test.npy\")\n",
        "\n",
        "data_set_name = \"mhsma\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guG1yPNmXL51"
      },
      "source": [
        "# Adapt for other y\n",
        "y_train = y_vacuole_train\n",
        "y_test = y_vacuole_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSBvHYo8paA_"
      },
      "source": [
        "### [Breast Cancer](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic))\n",
        "Beware: This data set does not consist of images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmFRpBnweJKx"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
        "x_train = x_train.reshape(x_train.shape + (1,))\n",
        "x_test = x_test.reshape(x_test.shape + (1,))\n",
        "data_set_name = \"breast_cancer\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RzpmUvo4UYU"
      },
      "source": [
        "## Create Auto-Keras model\n",
        "As the ImageClassifier is the only working classifier for version 0.4, it is used here for all data sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Nd-wKjU4UYV"
      },
      "source": [
        "%%time\n",
        "%tensorflow_version 1.x\n",
        "clf = ImageClassifier(verbose=True, augment=True, path=None, resume=False, searcher_args=None)\n",
        "clf.fit(x_train, y_train, time_limit=1 * 60 * 60) # 1 Hour\n",
        "clf.final_fit(x_train, y_train, x_test, y_test, retrain=False, trainer_args={'max_no_improvement_num': 5})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEijW2IK4UYe"
      },
      "source": [
        "### Export model\n",
        "You can export the model for later training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8-yWj0D4UYf"
      },
      "source": [
        "clf.export_autokeras_model(data_set_name + \".pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQPuvLb8Xd67"
      },
      "source": [
        "# Download model\n",
        "files.download(data_set_name + \".pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbpMWOFS4UYj"
      },
      "source": [
        "### Load model\n",
        "Note that when loading a model, the class of `clf` changes to `PortableImageSupervised`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1njzIuiXncv"
      },
      "source": [
        "# Upload model\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3kJkMGJ4UYk"
      },
      "source": [
        "clf = pickle_from_file(data_set_name + \".pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig08ml9fPncK"
      },
      "source": [
        "## Create model for comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgL_M_ZpaNfb"
      },
      "source": [
        "# Normalizing data\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255.\n",
        "x_test /= 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GuzpBVLLXL3"
      },
      "source": [
        "%%time\n",
        "%tensorflow_version 1.x\n",
        "# Creating a Sequential Model and adding the layers\n",
        "model = Sequential()\n",
        "model.add(Conv2D(28, kernel_size=(3,3), input_shape=x_train[0].shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(len(np.unique(y_test)), activation=\"softmax\"))\n",
        "\n",
        "# Train\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(x=x_train, y=y_train, epochs=10, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh8RjakbaUyM"
      },
      "source": [
        "## Visualize and Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae4tKWU1gbz2"
      },
      "source": [
        "### Auto-Keras model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6Zn3_n70-2i"
      },
      "source": [
        "# Evaluate\n",
        "print(clf.evaluate(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u71sI_hoZft7"
      },
      "source": [
        "torch_model = clf.cnn.best_model.produce_model() # For trained models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozPkQcMfA3Jj"
      },
      "source": [
        "torch_model = clf.graph.produce_model() # For portable models that got imported"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FJBmADKPE82"
      },
      "source": [
        "# Print model structure\n",
        "torch_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_5o3xRGPSSq"
      },
      "source": [
        "# Save and download model\n",
        "torch.save(torch_model, data_set_name + \".pth\")\n",
        "files.download(data_set_name + \".pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knAhUs0CP2rQ"
      },
      "source": [
        "Subsequently use [this website](https://lutzroeder.github.io/netron/) to visualize the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_ud7NW4giXw"
      },
      "source": [
        "### Keras model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti3CRT16fkPv"
      },
      "source": [
        "# Evaluate\n",
        "score = model.evaluate(x_test, y_test)\n",
        "print(\"Training loss\", score[0])\n",
        "print(\"Training accuracy\", score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cluP9xusgVuM"
      },
      "source": [
        "# Print model structure\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn_MiJv1g_WE"
      },
      "source": [
        "# Save and download model\n",
        "model.save(data_set_name + \".h5\")\n",
        "files.download(data_set_name + \".h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exz8NVdChk99"
      },
      "source": [
        "Subsequently use [this website](https://lutzroeder.github.io/netron/) to visualize the model."
      ]
    }
  ]
}